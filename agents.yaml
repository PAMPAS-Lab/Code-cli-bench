# agents.yaml
# Registry-style documentation for agents supported by run_agents.sh
# This file is *informational* (the bash script does not parse it);
# keep it as a single source of truth for commands/models and share with teammates.

agents:
  pywen:
    command: pywen
    modes: [headless, interactive]
    description: >
      Pywen CLI. In headless mode use `pywen [args] "PROMPT"`. In interactive
      mode run `pywen [args]` and use its REPL for multi-turn chat.
    args: "--pywen-args"
    model: "pywen-model"
    env:
      OPENAI_API_KEY: "env:OPENAI_API_KEY"
      OPENAI_BASE_URL: "${OPENAI_BASE_URL:-https://api.openai.com/v1}"
      PYWEN_EXTRA: "foo"

  claude-code:
    command: claude-code
    modes: [headless, interactive]
    description: >
      Anthropic's Claude Code CLI (you can rename or point CLAUDE_CMD env var
      to your own wrapper). Headless: `claude-code "PROMPT"`. Interactive:
      `claude-code` (REPL).
    args: "--claude-args"
    model: "claude-model"
    env:
      OPENAI_API_KEY: "env:OPENAI_API_KEY"
      OPENAI_BASE_URL: "${OPENAI_BASE_URL:-https://api.openai.com/v1}"
      PYWEN_EXTRA: "foo"

  openai-codex:
    command: openai-codex
    modes: [headless, interactive]
    description: >
      OpenAI Codex-style CLI placeholder (set CODEX_CMD env to your wrapper).
      Headless: `openai-codex "PROMPT"`. Interactive: `openai-codex`.
    args: "--openai-args"
    model: "openai-model"
    env:
      OPENAI_API_KEY: "env:OPENAI_API_KEY"
      OPENAI_BASE_URL: "${OPENAI_BASE_URL:-https://api.openai.com/v1}"
      PYWEN_EXTRA: "foo"
